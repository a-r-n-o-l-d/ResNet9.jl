var documenterSearchIndex = {"docs":
[{"location":"","page":"Home","title":"Home","text":"CurrentModule = ResNet9","category":"page"},{"location":"#ResNet9","page":"Home","title":"ResNet9","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"Documentation for ResNet9.","category":"page"},{"location":"","page":"Home","title":"Home","text":"","category":"page"},{"location":"","page":"Home","title":"Home","text":"Modules = [ResNet9]","category":"page"},{"location":"#ResNet9.resnet9-Tuple{Flux.Chain}","page":"Home","title":"ResNet9.resnet9","text":"resnet9(model::Chain; nclasses, dropout)\n\nBuild a ResNet9 model from an existing (pre-trained) model and change the first  or last layers according to inchannels, nclasses and dropout.\n\n\n\n\n\n","category":"method"},{"location":"#ResNet9.resnet9-Tuple{}","page":"Home","title":"ResNet9.resnet9","text":"resnet9(;inchannels, nclasses, basewidth = 64, expansion = 2)\n\nBuild a ResNet9 network.\n\ninchannels: number of input channels.\nnclasses: number of classes, if nclasses = 2 the network ends with a fully connected layer with a sigmoid activation function, otherwise it ends with a  fully connected layer followed by a softmax function.\nbasewidth: base number of channels.\nexpansion: factor of channels expansion.\n\n\n\n\n\n","category":"method"}]
}
